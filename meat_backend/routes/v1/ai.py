"""AI-01: ìœ¡ë¥˜ AI ë¶„ì„ ìš”ì²­ (multipart image, ocr/vision)."""
import logging
import os
from datetime import date, datetime, timedelta
from typing import Annotated

from fastapi import APIRouter, Depends, File, Form, HTTPException, status, UploadFile
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from ...config.database import get_db
from ...models.member import Member
from ...models.recognition_log import RecognitionLog
from ...models.fridge_item import FridgeItem
from ...models.meat_info import MeatInfo
from ...models.web_notification import WebNotification
from ...schemas.ai import AIAnalyzeResponse, AIMode
from ...services.ai_proxy import AIProxyService
from ...services.traceability import fetch_traceability
from ...middleware.jwt import get_current_user

router = APIRouter()
ai_proxy = AIProxyService()

MAX_IMAGE_SIZE = 5 * 1024 * 1024  # 5MB
ALLOWED_CONTENT_TYPES = {"image/jpeg", "image/png", "image/webp"}

logger = logging.getLogger(__name__)


@router.post(
    "/analyze",
    response_model=AIAnalyzeResponse,
    summary="AI-01 ìœ¡ë¥˜ AI ë¶„ì„ ìš”ì²­ (ì¸ì‹ì¼ +3ì¼ ìë™ ëƒ‰ì¥ê³  ì¶”ê°€)",
    responses={
        413: {"description": "íŒŒì¼ í¬ê¸° ì´ˆê³¼ (5MB ì œí•œ)"},
        415: {"description": "ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í¬ë§·"},
        422: {"description": "ì¸ì‹ ì‹¤íŒ¨ (ì¬ì´¬ì˜ ìš”ë§)"},
    },
)
async def ai_analyze(
    image: UploadFile = File(..., alias="image"),
    options: str | None = Form(None),
    auto_add_fridge: bool = Form(True, description="ì¸ì‹ í›„ ìë™ìœ¼ë¡œ ëƒ‰ì¥ê³ ì— ì¶”ê°€"),
    db: Annotated[AsyncSession, Depends(get_db)] = ...,
    member: Annotated[Member, Depends(get_current_user)] = ...,
):
    """AI ë¶„ì„ í›„ ì¸ì‹ì¼ ê¸°ì¤€ +3ì¼ë¡œ ìë™ ëƒ‰ì¥ê³  ì¶”ê°€."""
    ct = (image.content_type or "").lower()
    if ct and ct not in ALLOWED_CONTENT_TYPES:
        raise HTTPException(status_code=status.HTTP_415_UNSUPPORTED_MEDIA_TYPE, detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í¬ë§· (jpeg/png/webp)")
    try:
        raw = await image.read()
    except Exception as e:
        logger.exception("Image read error: %s", e)
        raise HTTPException(status_code=status.HTTP_422_UNPROCESSABLE_ENTITY, detail="ì´ë¯¸ì§€ ì½ê¸° ì‹¤íŒ¨")
    if len(raw) > MAX_IMAGE_SIZE:
        raise HTTPException(status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE, detail="íŒŒì¼ í¬ê¸° ì´ˆê³¼ (5MB ì œí•œ)")

    mode = "vision"
    if options:
        try:
            import json
            opts = json.loads(options) if isinstance(options, str) else options
            t = opts.get("type", "vision")
            if t in ("ocr", "vision"):
                mode = t
        except Exception:
            pass

    filename = image.filename or "image.jpg"
    out = await ai_proxy.analyze(raw, filename=filename, mode=mode)
    if out.get("error"):
        raise HTTPException(status_code=status.HTTP_422_UNPROCESSABLE_ENTITY, detail="ì¸ì‹ ì‹¤íŒ¨ (ì¬ì´¬ì˜ ìš”ë§)")

    part_name = out.get("partName")
    confidence = out.get("confidence", 0.0)
    history_no = out.get("historyNo")

    # recognition_logsì— ì €ì¥
    recognition_date = datetime.utcnow()
    log = RecognitionLog(
        member_id=member.id,
        image_url=filename,  # ì‹¤ì œë¡œëŠ” ì—…ë¡œë“œëœ ì´ë¯¸ì§€ URLì´ì–´ì•¼ í•¨
        part_name=part_name or "unknown",
        confidence_score=confidence,
        browser_agent=None,  # Requestì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ
    )
    db.add(log)
    await db.flush()

    # ì¶•ì‚°ë¬¼ ì´ë ¥ì œ API í˜¸ì¶œ (historyNoê°€ ìˆëŠ” ê²½ìš°)
    traceability_data = None
    if history_no:
        try:
            traceability_list = await fetch_traceability(history_no)
            if traceability_list and len(traceability_list) > 0:
                traceability_data = traceability_list[0]  # ì²« ë²ˆì§¸ ê²°ê³¼ ì‚¬ìš©
                logger.info(f"ì´ë ¥ì œ ì •ë³´ ì¡°íšŒ ì„±ê³µ: {traceability_data}")
        except Exception as e:
            logger.exception(f"ì´ë ¥ì œ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            # ì´ë ¥ì œ API ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (Mock ì‘ë‹µ ê°€ëŠ¥)

    fridge_item_id = None
    # part_nameì´ ìˆê³  auto_add_fridgeê°€ Trueë©´ ìë™ìœ¼ë¡œ ëƒ‰ì¥ê³ ì— ì¶”ê°€ (ì¸ì‹ì¼ +3ì¼)
    if part_name and auto_add_fridge and member:
        meat_result = await db.execute(select(MeatInfo).where(MeatInfo.part_name == part_name).limit(1))
        meat = meat_result.scalar_one_or_none()
        if meat:
            recognition_date_only = recognition_date.date()
            expiry_date = recognition_date_only + timedelta(days=3)  # ì¸ì‹ì¼ +3ì¼
            
            # ì´ë ¥ì œ ì •ë³´ì—ì„œ ë„ì¶•ì¼ì, ë“±ê¸‰ ì¶”ì¶œ
            slaughter_date = None
            grade = None
            origin = None
            company_name = None
            
            if traceability_data:
                # ë„ì¶•ì¼ì íŒŒì‹± (YYYY-MM-DD í˜•ì‹ ê°€ì •)
                slaughter_date_str = traceability_data.get("slaughterDate")
                if slaughter_date_str:
                    try:
                        slaughter_date = datetime.strptime(slaughter_date_str, "%Y-%m-%d").date()
                    except (ValueError, TypeError):
                        try:
                            # ë‹¤ë¥¸ í˜•ì‹ ì‹œë„
                            slaughter_date = datetime.strptime(slaughter_date_str[:10], "%Y-%m-%d").date()
                        except (ValueError, TypeError):
                            logger.warning(f"ë„ì¶•ì¼ì íŒŒì‹± ì‹¤íŒ¨: {slaughter_date_str}")
                
                grade = traceability_data.get("grade")
                origin = traceability_data.get("origin")
                company_name = traceability_data.get("companyName")
            
            fridge_item = FridgeItem(
                member_id=member.id,
                meat_info_id=meat.id,
                storage_date=recognition_date_only,
                expiry_date=expiry_date,
                status="stored",
                slaughter_date=slaughter_date,
                grade=grade,
                trace_number=history_no,
                origin=origin,
                company_name=company_name,
            )
            db.add(fridge_item)
            await db.flush()
            await db.refresh(fridge_item)
            fridge_item_id = fridge_item.id

            # ìœ í†µê¸°í•œ ì•Œë¦¼ ì˜ˆì•½ (3ì¼ í›„ 09:00)
            alert_time = datetime.combine(expiry_date, datetime.min.time().replace(hour=9))
            notification = WebNotification(
                member_id=member.id,
                fridge_item_id=fridge_item_id,
                notification_type="expiry_alert",
                title=f"{part_name} ìœ í†µê¸°í•œ ì„ë°•",
                body=f"{part_name}ì˜ ìœ í†µê¸°í•œì´ {expiry_date}ì…ë‹ˆë‹¤.",
                scheduled_at=alert_time,
                status="pending",
            )
            db.add(notification)
            await db.flush()

    return AIAnalyzeResponse(
        partName=part_name,
        confidence=confidence,
        historyNo=history_no,
        raw=out.get("raw"),
    )


class LLMRecipeRequest(BaseModel):
    fridgeItems: list[dict] = []


class LLMRecipeResponse(BaseModel):
    recipe: str


@router.post(
    "/recipe",
    response_model=LLMRecipeResponse,
    summary="LLM ë ˆì‹œí”¼ ìƒì„± (ëƒ‰ì¥ê³  ê³ ê¸° ê¸°ë°˜)",
    responses={
        401: {"description": "ì¸ì¦ í•„ìš”"},
    },
)
async def generate_recipe(
    body: LLMRecipeRequest,
    db: Annotated[AsyncSession, Depends(get_db)],
    member: Annotated[Member, Depends(get_current_user)],
):
    """í˜„ì¬ ëƒ‰ì¥ê³ ì˜ ê³ ê¸° ë¦¬ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLM ë ˆì‹œí”¼ ìƒì„±"""
    # ëƒ‰ì¥ê³  ì•„ì´í…œ ê°€ì ¸ì˜¤ê¸°
    q = (
        select(FridgeItem)
        .where(FridgeItem.member_id == member.id)
        .where(FridgeItem.status == "stored")
        .options(selectinload(FridgeItem.meat_info))
    )
    result = await db.execute(q)
    items = result.scalars().all()
    
    # ê³ ê¸° ë¶€ìœ„ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
    meat_parts = []
    for item in items:
        if item.meat_info:
            meat_parts.append(item.meat_info.part_name)
    
    if not meat_parts:
        return LLMRecipeResponse(
            recipe="# ë ˆì‹œí”¼ ì¶”ì²œ\n\ní˜„ì¬ ëƒ‰ì¥ê³ ì— ë³´ê´€ ì¤‘ì¸ ê³ ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤. ê³ ê¸°ë¥¼ ì¶”ê°€í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )
    
    # LLM API í˜¸ì¶œ (OpenAI ë˜ëŠ” Gemini)
    openai_api_key = os.getenv("OPENAI_API_KEY")
    gemini_api_key = os.getenv("GEMINI_API_KEY")
    
    meat_list_str = ", ".join(meat_parts)
    prompt = f"""í˜„ì¬ ëƒ‰ì¥ê³ ì— ìˆëŠ” ê³ ê¸° ë¶€ìœ„: {meat_list_str}

ì´ ê³ ê¸°ë“¤ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ë§›ìˆëŠ” ë ˆì‹œí”¼ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”. 
ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

# ë ˆì‹œí”¼ ì´ë¦„

## ì¬ë£Œ
- ì¬ë£Œ ëª©ë¡

## ì¡°ë¦¬ë²•
1. ì²« ë²ˆì§¸ ë‹¨ê³„
2. ë‘ ë²ˆì§¸ ë‹¨ê³„
...

## íŒ
- ì¡°ë¦¬ íŒì´ë‚˜ ì£¼ì˜ì‚¬í•­

í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    recipe_text = ""
    
    # OpenAI ì‚¬ìš©
    if openai_api_key:
        try:
            import openai
            client = openai.OpenAI(api_key=openai_api_key)
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ìš”ë¦¬ì‚¬ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ë ˆì‹œí”¼ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000,
            )
            recipe_text = response.choices[0].message.content
        except Exception as e:
            logger.exception(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            recipe_text = f"# ë ˆì‹œí”¼ ì¶”ì²œ\n\ní˜„ì¬ ëƒ‰ì¥ê³ ì— ìˆëŠ” ê³ ê¸°: {meat_list_str}\n\në ˆì‹œí”¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    # Gemini ì‚¬ìš© (OpenAI ì‹¤íŒ¨ ì‹œ)
    elif gemini_api_key:
        try:
            import google.generativeai as genai
            genai.configure(api_key=gemini_api_key)
            model = genai.GenerativeModel('gemini-pro')
            response = model.generate_content(prompt)
            recipe_text = response.text
        except Exception as e:
            logger.exception(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            recipe_text = f"# ë ˆì‹œí”¼ ì¶”ì²œ\n\ní˜„ì¬ ëƒ‰ì¥ê³ ì— ìˆëŠ” ê³ ê¸°: {meat_list_str}\n\në ˆì‹œí”¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    # LLM APIê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë ˆì‹œí”¼ ë°˜í™˜
    else:
        recipe_text = f"""# ê³ ê¸° ë ˆì‹œí”¼ ì¶”ì²œ

í˜„ì¬ ëƒ‰ì¥ê³ ì— ìˆëŠ” ê³ ê¸°: {meat_list_str}

## ì¶”ì²œ ë ˆì‹œí”¼

### 1. ê³ ê¸° ìš”ë¦¬
**ì¬ë£Œ:**
- {meat_list_str}
- ì†Œê¸ˆ, í›„ì¶”
- ì˜¬ë¦¬ë¸Œìœ 

**ì¡°ë¦¬ë²•:**
1. ê³ ê¸°ë¥¼ ì‹¤ì˜¨ì— 30ë¶„ê°„ ë‘ì–´ ì˜¨ë„ë¥¼ ë§ì¶¥ë‹ˆë‹¤.
2. ì†Œê¸ˆê³¼ í›„ì¶”ë¡œ ê°„ì„ í•©ë‹ˆë‹¤.
3. íŒ¬ì„ ë‹¬êµ° ë’¤ ì˜¬ë¦¬ë¸Œìœ ë¥¼ ë‘ë¦…ë‹ˆë‹¤.
4. ê³ ê¸°ë¥¼ ë„£ê³  ê° ë©´ì„ 2-3ë¶„ì”© êµ½ìŠµë‹ˆë‹¤.
5. 5ë¶„ê°„ íœ´ì§€ì‹œí‚¨ í›„ ì œê³µí•©ë‹ˆë‹¤.

ë§›ìˆê²Œ ë“œì„¸ìš”! ğŸ¥©"""

    return LLMRecipeResponse(recipe=recipe_text)
